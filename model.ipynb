{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pandas.core.common import flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(MyModel, self).__init__()\n",
    "\n",
    "#         # Define the layers of the network\n",
    "#         self.conv1 = nn.Conv2d(\n",
    "#             in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=1\n",
    "#         )\n",
    "#         self.relu1 = nn.ReLU(inplace=True)\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(\n",
    "#             in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1\n",
    "#         )\n",
    "#         self.relu2 = nn.ReLU(inplace=True)\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(\n",
    "#             in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1\n",
    "#         )\n",
    "#         self.relu3 = nn.ReLU(inplace=True)\n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv4 = nn.Conv2d(\n",
    "#             in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1\n",
    "#         )\n",
    "#         self.relu4 = nn.ReLU(inplace=True)\n",
    "#         self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.fc4 = nn.Linear(in_features=256 * 16 * 16, out_features=512)\n",
    "#         self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "#         self.fc5 = nn.Linear(in_features=512, out_features=num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass the input through the layers of the network\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.pool2(x)\n",
    "\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.pool3(x)\n",
    "\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.relu4(x)\n",
    "#         x = self.pool4(x)\n",
    "\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.relu4(x)\n",
    "\n",
    "#         x = self.fc5(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the ResNet-based CNN model\n",
    "# class ResNetCNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(ResNetCNN, self).__init__()\n",
    "        \n",
    "#         # Load the pre-trained ResNet-18 model\n",
    "#         resnet = models.resnet152(pretrained=True)\n",
    "        \n",
    "#         # Remove the last fully connected layer\n",
    "#         modules = list(resnet.children())[:-1]\n",
    "#         self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "#         # Add a new fully connected layer\n",
    "#         self.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass the input through the ResNet model\n",
    "#         x = self.resnet(x)\n",
    "        \n",
    "#         # Flatten the output tensor\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Pass the output through the fully connected layer\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 directories and 0 images in Dataset\n",
      "There are 0 directories and 1000 images in Dataset\\test\n",
      "There are 36 directories and 0 images in Dataset\\train\n",
      "There are 0 directories and 22 images in Dataset\\train\\class_0\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_1\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_2\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_3\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_4\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_5\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_6\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_7\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_8\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_9\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_A\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_B\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_C\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_D\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_E\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_F\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_G\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_H\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_I\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_J\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_K\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_L\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_M\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_N\n",
      "There are 0 directories and 26 images in Dataset\\train\\class_O\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_P\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_Q\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_R\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_S\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_T\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_U\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_V\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_W\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_X\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_Y\n",
      "There are 0 directories and 24 images in Dataset\\train\\class_Z\n",
      "There are 36 directories and 0 images in Dataset\\val\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_0\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_1\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_2\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_3\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_4\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_5\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_6\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_7\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_8\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_9\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_A\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_B\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_C\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_D\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_E\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_F\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_G\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_H\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_I\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_J\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_K\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_L\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_M\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_N\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_O\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_P\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_Q\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_R\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_S\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_T\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_U\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_V\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_W\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_X\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_Y\n",
      "There are 0 directories and 6 images in Dataset\\val\\class_Z\n",
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'\n",
      " 'I' 'J' 'K' 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(\"Dataset\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "\n",
    "bean_class = len(os.listdir(\"data/train/\"))\n",
    "\n",
    "dataset_dir = pathlib.Path(\"data/train\")\n",
    "class_names = np.array(sorted([item.name for item in dataset_dir.glob(\"*\")]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameters and optimizer\n",
    "num_epochs = 32\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "num_classes = 35\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229,0.224,0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the dataset\n",
    "train_set = datasets.ImageFolder(root='data/train', transform=transform)\n",
    "\n",
    "# Define a data loader to iterate over the dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the dataset\n",
    "val_set = datasets.ImageFolder(root='Dataset/val/', transform=transform)\n",
    "\n",
    "# Define a data loader to iterate over the dataset\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the dataset\n",
    "test_set = datasets.ImageFolder(root='data/test', transform=transform)\n",
    "\n",
    "# Define a data loader to iterate over the dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13672\\3906865748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mtrain_ground_truths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ground_truths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "# Iterate over the validation dataset in batches\n",
    "train_predictions = np.array([])\n",
    "train_ground_truths = np.array([])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_losses.append(train_loss/train_total)\n",
    "    train_accs.append(train_correct/train_total)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            train_predictions = np.concatenate((train_predictions, predicted.cpu().numpy()))\n",
    "            train_ground_truths = np.concatenate((train_ground_truths, labels.cpu().numpy()))\n",
    "\n",
    "            \n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # remove the extra predictions\n",
    "        if len(train_predictions) > len(train_ground_truths):\n",
    "            train_predictions = train_predictions[:len(train_ground_truths)]\n",
    "\n",
    "    # Convert predictions and true labels to numpy arrays\n",
    "    train_predictions = np.array(train_predictions)\n",
    "    train_ground_truths = np.array(train_ground_truths)\n",
    "    \n",
    "    val_losses.append(val_loss/val_total)\n",
    "    val_accs.append(val_correct/val_total)\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_losses[-1], train_accs[-1], val_losses[-1], val_accs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        predictions.extend(predicted.numpy())\n",
    "        ground_truths.extend(labels.numpy())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print('Validating Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(ground_truths, predictions)\n",
    "labels_category = ['0', '1', '2', '3', '4', '5', '6','7', '8', '9', 'A', 'B', 'C', 'D','E', 'F', 'G', 'H', 'I', 'J', 'K','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels= labels_category, yticklabels=labels_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[Epoch %d, Batch %5d] Loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print('Training Accuracy: {:.2f}%'.format(train_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions.extend(predicted.numpy())\n",
    "        ground_truths.extend(labels.numpy())\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print('Testing Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a68dd9e53dbf6c071ff37c90cd6a2970e03ca2d570d58a51cba255663b249748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
